# ğŸš€ PortProject_API â€“ Crypto ETL Pipeline (Manual Version)

This project is an ETL (Extract, Transform, Load) pipeline for retrieving cryptocurrency market data from [CoinGecko API](https://www.coingecko.com/en/api), enriching and cleaning the dataset, and uploading it to Google BigQuery.

> âš ï¸ **Note:** Prefect orchestration is included but **not yet active**. Run the pipeline manually using `main.py`.

---

## ğŸ“ Project Structure

```text
PortProject_API/
â”œâ”€â”€ etl/
|   â”œâ”€â”€ extract.py # Extracts data from CoinGecko API
|   â””â”€â”€ transform.py # Cleans & enriches the data
|   â””â”€â”€ load.py # Uploads data to BigQuery
|   â””â”€â”€ main.py
|   â””â”€â”€ etl_pipeline_prefect.py # Prefect pipeline (not yet active)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ api-crypto-dashboard-xxx.json # GCP credentials (keep private)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_crypto.csv
â”‚   â””â”€â”€ clean_crypto.csv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

### âš™ï¸ How to Run (Manual Mode)
Install dependencies:
```bash
pip install -r requirements.txt
```
Run ETL pipeline:
```bash
python main.py
```
#### ğŸ“ Notes
  1. Store your GCP service account key in:
  ```config/api-crypto-dashboard-xxx.json```

  2. Data output files are stored in /data (ignored by git).

  3. Do not share your credentials publicly.

#### âœ… Deployment Checklist
   âœ…Manual pipeline works (main.py)

   Prefect orchestration tested & activated

   Automated scheduling via Prefect

#### ğŸ“¦ Requirements
List in requirements.txt:
```nginx
pandas
requests
pandas-gbq
google-cloud-bigquery
google-auth
prefect
```
Install with:
```bash
pip install -r requirements.txt
```

ğŸ‘¨â€ğŸ’» Author
Made with â¤ï¸ by [Muhamad Dimas Wijaya Kesuma]
