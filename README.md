#  Crypto ETL Pipeline (Manual Version)

This project is an ETL (Extract, Transform, Load) pipeline for retrieving cryptocurrency market data from the [CoinGecko API](https://www.coingecko.com/en/api), enriching and cleaning the dataset, and uploading it to Google BigQuery.

> âš ï¸ **Note:** The ETL workflow is structured for [Prefect](https://docs.prefect.io/), but Prefect orchestration is **not yet active**. The pipeline can currently be run manually step-by-step.

---

## ğŸ“ Project Structure
PortProject_API/
etl/
  â”œâ”€â”€ extract.py                    # Extracts data from CoinGecko API
  â”œâ”€â”€ transform.py                  # Cleans & enriches the data
  â”œâ”€â”€ load.py                       # Uploads data to BigQuery
  â”œâ”€â”€ main.py                       # Runs the ETL pipeline (manual)
  â”œâ”€â”€ etl_pipeline_prefect.py       # Prefect pipeline (not yet active)
â”œâ”€â”€ config/
  â”‚   â””â”€â”€ api-crypto-dashboard-xxx.json   # GCP credentials (keep private)
â”œâ”€â”€ data/
  â”‚   â”œâ”€â”€ raw_crypto.csv            # Raw data (output, ignored)
  â”‚   â””â”€â”€ clean_crypto.csv          # Cleaned/enriched data (output, ignored)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## âš™ï¸ How to Run (Manual Mode)

### 1. Install Dependencies

```bash
  pip install -r requirements.txt

**2. Run Each Step**
Extract:
```bash 
  python extract.py

Transform:
```bash
  python transform.py

Load:
```python
  from load import load_to_bigquery
  import pandas as pd

  df = pd.read_csv("data/clean_crypto.csv")
  load_to_bigquery(df)


ğŸ§ª Prefect Pipeline (Not Yet Active)
The file etl_pipeline_prefect.py is set up for Prefect orchestration, but Prefect is not yet configured and tested in this repo.
Once Prefect is configured, you can run the entire ETL flow with:
```bash
  python etl_pipeline_prefect.py

ğŸ“ Notes
- Store your GCP service account key in: config/api-crypto-dashboard-xxx.json

- This file is already excluded in .gitignore

- Make sure your BigQuery project and tables are set up and accessible

- Do not share your credentials publicly


âœ… Deployment Checklist:

 - Manual pipeline works (extract, transform, load) âœ…

 - Prefect CLI & agent installed

 - Prefect pipeline tested end-to-end

 - Automated scheduling via Prefect Cloud or local agent

ğŸ“¦ Requirements
List in requirements.txt:
```nginx
  pandas
  requests
  pandas-gbq
  google-cloud-bigquery
  google-auth
  prefect

ğŸ‘¨â€ğŸ’» Author
Made with â¤ï¸ by [Muhamad Dimas Wijaya Kesuma]
